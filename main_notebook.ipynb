{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WzUCo5fJdbO4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import seaborn as sns\n",
        "from src import *\n",
        "import torchsummary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou1scoZfbltP",
        "outputId": "c8069c8a-fa99-4028-8cda-9b57e22bb47f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I file sono stati estratti in: C:\\Users\\gcusumano\\ProfAI\\GourmetAI\n"
          ]
        }
      ],
      "source": [
        "download_and_unzip(\"https://proai-datasets.s3.eu-west-3.amazonaws.com/dataset_food_classification.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nJ2nqRlmdSGe"
      },
      "outputs": [],
      "source": [
        "class Transforms:\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, img, *args, **kwargs):\n",
        "        return self.transforms(image=np.array(img))['image']\n",
        "\n",
        "transform = A.Compose([\n",
        "        A.Resize(256, 256),\n",
        "        A.HorizontalFlip(),\n",
        "        A.VerticalFlip(),\n",
        "        A.Rotate(limit=90),\n",
        "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1),\n",
        "        A.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "        ToTensorV2(),\n",
        "      ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wQzscBNVhTF1"
      },
      "outputs": [],
      "source": [
        "trainset = torchvision.datasets.ImageFolder(root='dataset/train', transform=Transforms(transform))\n",
        "\n",
        "valset = torchvision.datasets.ImageFolder(root='dataset/val', transform=Transforms(transform))\n",
        "\n",
        "testset = torchvision.datasets.ImageFolder(root='dataset/test',transform=Transforms(transform))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGH1S9XphWP-",
        "outputId": "b23e77fa-970e-437d-df8d-768e392fe343"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8960, 2240, 2800)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(trainset), len(valset), len(testset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tmRwbkfZhd6_"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "N9b_GjsxhkaY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\gcusumano\\ProfAI\\GourmetAI\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\gcusumano\\ProfAI\\GourmetAI\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 256, 256]           1,792\n",
            "              ReLU-2         [-1, 64, 256, 256]               0\n",
            "            Conv2d-3         [-1, 64, 256, 256]          36,928\n",
            "              ReLU-4         [-1, 64, 256, 256]               0\n",
            "         MaxPool2d-5         [-1, 64, 128, 128]               0\n",
            "            Conv2d-6        [-1, 128, 128, 128]          73,856\n",
            "              ReLU-7        [-1, 128, 128, 128]               0\n",
            "            Conv2d-8        [-1, 128, 128, 128]         147,584\n",
            "              ReLU-9        [-1, 128, 128, 128]               0\n",
            "        MaxPool2d-10          [-1, 128, 64, 64]               0\n",
            "           Conv2d-11          [-1, 256, 64, 64]         295,168\n",
            "             ReLU-12          [-1, 256, 64, 64]               0\n",
            "           Conv2d-13          [-1, 256, 64, 64]         590,080\n",
            "             ReLU-14          [-1, 256, 64, 64]               0\n",
            "           Conv2d-15          [-1, 256, 64, 64]         590,080\n",
            "             ReLU-16          [-1, 256, 64, 64]               0\n",
            "        MaxPool2d-17          [-1, 256, 32, 32]               0\n",
            "           Conv2d-18          [-1, 512, 32, 32]       1,180,160\n",
            "             ReLU-19          [-1, 512, 32, 32]               0\n",
            "           Conv2d-20          [-1, 512, 32, 32]       2,359,808\n",
            "             ReLU-21          [-1, 512, 32, 32]               0\n",
            "           Conv2d-22          [-1, 512, 32, 32]       2,359,808\n",
            "             ReLU-23          [-1, 512, 32, 32]               0\n",
            "        MaxPool2d-24          [-1, 512, 16, 16]               0\n",
            "           Conv2d-25          [-1, 512, 16, 16]       2,359,808\n",
            "             ReLU-26          [-1, 512, 16, 16]               0\n",
            "           Conv2d-27          [-1, 512, 16, 16]       2,359,808\n",
            "             ReLU-28          [-1, 512, 16, 16]               0\n",
            "           Conv2d-29          [-1, 512, 16, 16]       2,359,808\n",
            "             ReLU-30          [-1, 512, 16, 16]               0\n",
            "        MaxPool2d-31            [-1, 512, 8, 8]               0\n",
            "AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n",
            "           Linear-33                 [-1, 4096]     102,764,544\n",
            "             ReLU-34                 [-1, 4096]               0\n",
            "          Dropout-35                 [-1, 4096]               0\n",
            "           Linear-36                 [-1, 4096]      16,781,312\n",
            "             ReLU-37                 [-1, 4096]               0\n",
            "          Dropout-38                 [-1, 4096]               0\n",
            "           Linear-39                   [-1, 14]          57,358\n",
            "================================================================\n",
            "Total params: 134,317,902\n",
            "Trainable params: 57,358\n",
            "Non-trainable params: 134,260,544\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 285.63\n",
            "Params size (MB): 512.38\n",
            "Estimated Total Size (MB): 798.76\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "vgg = models.vgg16(pretrained=True)\n",
        "\n",
        "for param in vgg.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "last_layer = vgg.classifier[-1]\n",
        "last_layer_n_features = last_layer.in_features\n",
        "classes = trainset.classes\n",
        "vgg.classifier[-1] = nn.Linear(last_layer_n_features, len(classes))\n",
        "torchsummary.summary(vgg,(3,256,256))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import shutil\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "import importlib\n",
        "\n",
        "def get_logger(ch_log_level=logging.ERROR, \n",
        "               fh_log_level=logging.INFO):\n",
        "    logging.shutdown()\n",
        "    importlib.reload(logging)  # Sostituito imp.reload con importlib.reload\n",
        "    logger = logging.getLogger(\"cheatsheet\")\n",
        "    logger.setLevel(logging.DEBUG)\n",
        "    \n",
        "    # Console Handler\n",
        "    if ch_log_level:\n",
        "        ch = logging.StreamHandler()\n",
        "        ch.setLevel(ch_log_level)\n",
        "        ch.setFormatter(logging.Formatter('%(message)s'))\n",
        "        logger.addHandler(ch)\n",
        "    \n",
        "    # File Handler\n",
        "    if fh_log_level:\n",
        "        fh = logging.FileHandler('cheatsheet.log')\n",
        "        fh.setLevel(fh_log_level)\n",
        "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "        fh.setFormatter(formatter)\n",
        "        logger.addHandler(fh)\n",
        "\n",
        "    return logger\n",
        "\n",
        "class Experiment():\n",
        "    def __init__(self, name, root, logger=None):\n",
        "        self.name = name\n",
        "        self.root = os.path.join(root, name)\n",
        "        self.logger = logger\n",
        "        self.epoch = 1\n",
        "        self.best_val_loss = sys.maxsize\n",
        "        self.best_val_loss_epoch = 1\n",
        "        self.weights_dir = os.path.join(self.root, 'weights')\n",
        "        self.history_dir = os.path.join(self.root, 'history')\n",
        "        self.results_dir = os.path.join(self.root, 'results')\n",
        "        self.latest_weights = os.path.join(self.weights_dir, 'latest_weights.pth')\n",
        "        self.latest_optimizer = os.path.join(self.weights_dir, 'latest_optim.pth')\n",
        "        self.best_weights_path = self.latest_weights\n",
        "        self.best_optimizer_path = self.latest_optimizer\n",
        "        self.train_history_fpath = os.path.join(self.history_dir, 'train.csv')\n",
        "        self.val_history_fpath = os.path.join(self.history_dir, 'val.csv')\n",
        "        self.test_history_fpath = os.path.join(self.history_dir, 'test.csv')\n",
        "        self.loss_history = {\n",
        "            'train': np.array([]),\n",
        "            'val': np.array([]),\n",
        "            'test': np.array([])\n",
        "        }\n",
        "        self.acc_history = {\n",
        "            'train': np.array([]),\n",
        "            'val': np.array([]),\n",
        "            'test': np.array([])\n",
        "        }\n",
        "        \n",
        "    def log(self, msg):\n",
        "        if self.logger:\n",
        "            self.logger.info(msg)\n",
        "        \n",
        "    def init(self):\n",
        "        self.log(\"Creating new experiment\")\n",
        "        self.init_dirs()\n",
        "        self.init_history_files()\n",
        "\n",
        "    def resume(self, model, optim, weights_fpath=None, optim_path=None):\n",
        "        self.log(\"Resuming existing experiment\")\n",
        "        if weights_fpath is None:\n",
        "            weights_fpath = self.latest_weights\n",
        "        if optim_path is None:\n",
        "            optim_path = self.latest_optimizer\n",
        "\n",
        "        model, state = self.load_weights(model, weights_fpath)\n",
        "        optim = self.load_optimizer(optim, optim_path)\n",
        "\n",
        "        self.best_val_loss = state['best_val_loss']\n",
        "        self.best_val_loss_epoch = state['best_val_loss_epoch']\n",
        "        self.epoch = state['last_epoch'] + 1\n",
        "        self.load_history_from_file('train')\n",
        "        self.load_history_from_file('val')\n",
        "\n",
        "        return model, optim\n",
        "\n",
        "    def init_dirs(self):\n",
        "        os.makedirs(self.weights_dir, exist_ok=True)\n",
        "        os.makedirs(self.history_dir, exist_ok=True)\n",
        "        os.makedirs(self.results_dir, exist_ok=True)\n",
        "        \n",
        "    def init_history_files(self):\n",
        "        Path(self.train_history_fpath).touch()\n",
        "        Path(self.val_history_fpath).touch()\n",
        "        Path(self.test_history_fpath).touch()\n",
        "\n",
        "    def load_history_from_file(self, dset_type):\n",
        "        fpath = os.path.join(self.history_dir, dset_type + '.csv')\n",
        "        try:\n",
        "            data = np.loadtxt(fpath, delimiter=',').reshape(-1, 3)\n",
        "            self.loss_history[dset_type] = data[:, 1]\n",
        "            self.acc_history[dset_type] = data[:, 2]\n",
        "        except:\n",
        "            self.loss_history[dset_type] = np.array([])\n",
        "            self.acc_history[dset_type] = np.array([])\n",
        "\n",
        "    def append_history_to_file(self, dset_type, loss, acc):\n",
        "        fpath = os.path.join(self.history_dir, dset_type + '.csv')\n",
        "        with open(fpath, 'a') as f:\n",
        "            f.write('{},{},{}\\n'.format(self.epoch, loss, acc))\n",
        "\n",
        "    def save_history(self, dset_type, loss, acc):\n",
        "        self.loss_history[dset_type] = np.append(\n",
        "            self.loss_history[dset_type], loss)\n",
        "        self.acc_history[dset_type] = np.append(\n",
        "            self.acc_history[dset_type], acc)\n",
        "        self.append_history_to_file(dset_type, loss, acc)\n",
        "\n",
        "        if dset_type == 'val' and self.is_best_loss(loss):\n",
        "            self.best_val_loss = loss\n",
        "            self.best_val_loss_epoch = self.epoch\n",
        "            \n",
        "        # Plot and save after each update\n",
        "        self.plot_and_save_history()\n",
        "\n",
        "    def is_best_loss(self, loss):\n",
        "        return loss < self.best_val_loss\n",
        "\n",
        "    def save_weights(self, model, trn_loss, val_loss, trn_acc, val_acc):\n",
        "        weights_fname = self.name + '-weights-%d-%.3f-%.3f-%.3f-%.3f.pth' % (\n",
        "            self.epoch, trn_loss, trn_acc, val_loss, val_acc)\n",
        "        weights_fpath = os.path.join(self.weights_dir, weights_fname)\n",
        "        torch.save({\n",
        "            'last_epoch': self.epoch,\n",
        "            'trn_loss': trn_loss,\n",
        "            'val_loss': val_loss,\n",
        "            'trn_acc': trn_acc,\n",
        "            'val_acc': val_acc,\n",
        "            'best_val_loss': self.best_val_loss,\n",
        "            'best_val_loss_epoch': self.best_val_loss_epoch,\n",
        "            'experiment': self.name,\n",
        "            'state_dict': model.state_dict()\n",
        "        }, weights_fpath)\n",
        "        shutil.copyfile(weights_fpath, self.latest_weights)\n",
        "        if self.is_best_loss(val_loss):\n",
        "            self.best_weights_path = weights_fpath\n",
        "\n",
        "    def load_weights(self, model, fpath):\n",
        "        self.log(\"loading weights '{}'\".format(fpath))\n",
        "        state = torch.load(fpath)\n",
        "        model.load_state_dict(state['state_dict'])\n",
        "        self.log(\"loaded weights from experiment %s (last_epoch %d, trn_loss %s, trn_acc %s, val_loss %s, val_acc %s)\" % (\n",
        "            self.name, state['last_epoch'], state['trn_loss'],\n",
        "            state['trn_acc'], state['val_loss'], state['val_acc']))\n",
        "        return model, state\n",
        "\n",
        "    def save_optimizer(self, optimizer, val_loss):\n",
        "        optim_fname = self.name + '-optim-%d.pth' % (self.epoch)\n",
        "        optim_fpath = os.path.join(self.weights_dir, optim_fname)\n",
        "        torch.save({\n",
        "            'last_epoch': self.epoch,\n",
        "            'experiment': self.name,\n",
        "            'state_dict': optimizer.state_dict()\n",
        "        }, optim_fpath)\n",
        "        shutil.copyfile(optim_fpath, self.latest_optimizer)\n",
        "        if self.is_best_loss(val_loss):\n",
        "            self.best_optimizer_path = optim_fpath\n",
        "\n",
        "    def load_optimizer(self, optimizer, fpath):\n",
        "        self.log(\"loading optimizer '{}'\".format(fpath))\n",
        "        optim = torch.load(fpath)\n",
        "        optimizer.load_state_dict(optim['state_dict'])\n",
        "        self.log(\"loaded optimizer from session {}, last_epoch {}\"\n",
        "                 .format(optim['experiment'], optim['last_epoch']))\n",
        "        return optimizer\n",
        "    \n",
        "    def plot_and_save_history(self):\n",
        "        \"\"\"Plot and save training history after each epoch\"\"\"\n",
        "        if len(self.loss_history['train']) == 0:\n",
        "            return\n",
        "            \n",
        "        epochs = range(1, self.epoch + 1)\n",
        "        \n",
        "        # Create figure with two subplots side by side\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "        \n",
        "        # Plot loss\n",
        "        ax1.plot(epochs, self.loss_history['train'], label='Train')\n",
        "        if len(self.loss_history['val']) > 0:\n",
        "            ax1.plot(epochs, self.loss_history['val'], label='Validation')\n",
        "        ax1.set_xlabel('Epoch')\n",
        "        ax1.set_ylabel('Loss')\n",
        "        ax1.set_yscale('log')\n",
        "        ax1.legend()\n",
        "        ax1.grid(True)\n",
        "        \n",
        "        # Plot accuracy\n",
        "        ax2.plot(epochs, self.acc_history['train'], label='Train')\n",
        "        if len(self.acc_history['val']) > 0:\n",
        "            ax2.plot(epochs, self.acc_history['val'], label='Validation')\n",
        "        ax2.set_xlabel('Epoch')\n",
        "        ax2.set_ylabel('Accuracy')\n",
        "        ax2.legend()\n",
        "        ax2.grid(True)\n",
        "        \n",
        "        # Add title\n",
        "        fig.suptitle(f'Training History - {self.name}')\n",
        "        \n",
        "        # Adjust layout and save\n",
        "        plt.tight_layout()\n",
        "        history_plot_path = os.path.join(self.history_dir, 'training_history.png')\n",
        "        plt.savefig(history_plot_path)\n",
        "        plt.close()\n",
        "        \n",
        "        # Log current metrics\n",
        "        self.log(f\"Epoch {self.epoch}:\")\n",
        "        self.log(f\"Train - Loss: {self.loss_history['train'][-1]:.4f}, Acc: {self.acc_history['train'][-1]:.4f}\")\n",
        "        if len(self.loss_history['val']) > 0:\n",
        "            self.log(f\"Val - Loss: {self.loss_history['val'][-1]:.4f}, Acc: {self.acc_history['val'][-1]:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### New Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Creating new experiment\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  + Number of params: 134317902\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 2\n",
        "MAX_PATIENCE = 5\n",
        "LEARNING_RATE = 1e-4\n",
        "LR_DECAY = 0.995\n",
        "DECAY_LR_EVERY_N_EPOCHS = 1\n",
        "EXPERIMENT_NAME = 'exp1'\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = vgg.to(device)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "logger = get_logger(ch_log_level=logging.INFO, fh_log_level=logging.INFO)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "print('  + Number of params: {}'.format(\n",
        "    sum([p.data.nelement() for p in model.parameters()])))\n",
        "exp = Experiment(EXPERIMENT_NAME, \"exps\", logger)\n",
        "\n",
        "# Create New Experiment\n",
        "exp.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import os\n",
        "\n",
        "def train(net, dataloader, criterion, optimizer, epoch=1):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    net.train()\n",
        "    n_batches = len(dataloader)\n",
        "    total_loss = 0\n",
        "    total_acc = 0\n",
        "    for inputs,targets in dataloader:\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        \n",
        "        ## Forward Pass\n",
        "        output = net(inputs)\n",
        "        \n",
        "        ## Clear Gradients\n",
        "        net.zero_grad()\n",
        "        \n",
        "        loss = criterion(output, targets)\n",
        "    \n",
        "        ## Backprop\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "        preds = get_predictions(output)\n",
        "        accuracy = get_accuracy(preds, targets.data.cpu().numpy())\n",
        "    \n",
        "        total_loss += loss.item()\n",
        "        total_acc += accuracy\n",
        "    \n",
        "    mean_loss = total_loss / n_batches\n",
        "    mean_acc = total_acc / n_batches\n",
        "    return mean_loss, mean_acc\n",
        "\n",
        "def get_predictions(model_output):\n",
        "    # Flatten and Get ArgMax to compute accuracy\n",
        "    val,idx = torch.max(model_output, dim=1)\n",
        "    return idx.data.cpu().view(-1).numpy()\n",
        "\n",
        "def get_accuracy(preds, targets):\n",
        "    correct = np.sum(preds==targets)\n",
        "    return correct / len(targets)\n",
        "\n",
        "def test(net, test_loader, criterion, epoch=1):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    test_acc = 0\n",
        "    with torch.no_grad():  # Disabilita il calcolo dei gradienti\n",
        "        for data, target in test_loader:\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            output = net(data)  # Calcola le previsioni del modello\n",
        "            test_loss += criterion(output, target).item()  # Calcola la perdita\n",
        "\n",
        "            pred = get_predictions(output)  # Ottieni le previsioni dal modello\n",
        "            test_acc += get_accuracy(pred, target.cpu().numpy())  # Calcola l'accuratezza\n",
        "    test_loss /= len(test_loader) #n_batches\n",
        "    test_acc /= len(test_loader)\n",
        "    return test_loss, test_acc\n",
        "\n",
        "def adjust_learning_rate(lr, decay, optimizer, cur_epoch, n_epochs):\n",
        "    \"\"\"Sets the learning rate to the initially \n",
        "        configured `lr` decayed by `decay` every `n_epochs`\"\"\"\n",
        "    new_lr = lr * (decay ** (cur_epoch // n_epochs))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = new_lr\n",
        "\n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        init.kaiming_uniform(m.weight) \n",
        "        m.bias.data.zero_()\n",
        "\n",
        "def save_weights(model, weights_dir, epoch):\n",
        "    weights_fname = 'weights-%d.pth' % (epoch)\n",
        "    weights_fpath = os.path.join(weights_dir, weights_fname)\n",
        "    torch.save({'state_dict': model.state_dict()}, weights_fpath)\n",
        "\n",
        "def load_weights(model, fpath):\n",
        "    model.load_state_dict(state['state_dict'])\n",
        "    state = torch.load(fpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[11], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m since \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m### Train ###\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m trn_loss, trn_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{:d}\u001b[39;00m\u001b[38;5;124m: Train - Loss: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mAcc: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch, trn_loss, trn_acc))    \n\u001b[0;32m      9\u001b[0m time_elapsed \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m since  \n",
            "Cell \u001b[1;32mIn[10], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(net, dataloader, criterion, optimizer, epoch)\u001b[0m\n\u001b[0;32m     16\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m## Forward Pass\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m## Clear Gradients\u001b[39;00m\n\u001b[0;32m     22\u001b[0m net\u001b[38;5;241m.\u001b[39mzero_grad()\n",
            "File \u001b[1;32mc:\\Users\\gcusumano\\ProfAI\\GourmetAI\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\gcusumano\\ProfAI\\GourmetAI\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\gcusumano\\ProfAI\\GourmetAI\\.venv\\Lib\\site-packages\\torchvision\\models\\vgg.py:66\u001b[0m, in \u001b[0;36mVGG.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m---> 66\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[0;32m     68\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\gcusumano\\ProfAI\\GourmetAI\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\gcusumano\\ProfAI\\GourmetAI\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\gcusumano\\ProfAI\\GourmetAI\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\gcusumano\\ProfAI\\GourmetAI\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\gcusumano\\ProfAI\\GourmetAI\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\gcusumano\\ProfAI\\GourmetAI\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\gcusumano\\ProfAI\\GourmetAI\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "for epoch in range(exp.epoch, exp.epoch+N_EPOCHS):\n",
        "    since = time.time()\n",
        "\n",
        "    ### Train ###\n",
        "    trn_loss, trn_acc = train(model, trainloader, criterion, optimizer, epoch)\n",
        "    logger.info('Epoch {:d}: Train - Loss: {:.4f}\\tAcc: {:.4f}'.format(epoch, trn_loss, trn_acc))    \n",
        "    time_elapsed = time.time() - since  \n",
        "    logger.info('Train Time {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    \n",
        "    ### Test ###\n",
        "    val_loss, val_acc = test(model, testloader, criterion, epoch)    \n",
        "    logger.info('Val - Loss: {:.4f}, Acc: {:.4f}'.format(val_loss, val_acc))\n",
        "    time_elapsed = time.time() - since  \n",
        "    logger.info('Total Time {:.0f}m {:.0f}s\\n'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "    ### Save Metrics ###\n",
        "    exp.save_history('train', trn_loss, trn_acc)\n",
        "    exp.save_history('val', val_loss, val_acc)\n",
        "    \n",
        "    ### Checkpoint ###    \n",
        "    exp.save_weights(model, trn_loss, val_loss, trn_acc, val_acc)\n",
        "    exp.save_optimizer(optimizer, val_loss)\n",
        "    \n",
        "    ### Plot Online ###\n",
        "    exp.update_viz_loss_plot()\n",
        "    exp.update_viz_acc_plot()\n",
        "    exp.update_viz_summary_plot()\n",
        "    \n",
        "    ## Early Stopping ##\n",
        "    if (epoch - exp.best_val_loss_epoch) > MAX_PATIENCE:\n",
        "        logger.info((\"Early stopping at epoch %d since no \" \n",
        "               + \"better loss found since epoch %.3\") \n",
        "               % (epoch, exp.best_val_loss))\n",
        "        break\n",
        "\n",
        "    ### Adjust Lr ###\n",
        "    adjust_learning_rate(LEARNING_RATE, LR_DECAY, optimizer, \n",
        "                         epoch, DECAY_LR_EVERY_N_EPOCHS)\n",
        "    \n",
        "    exp.epoch += 1"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
